{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "action.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "A8aBbXJPXciC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sggoIcb0Xsw8",
        "colab_type": "code",
        "outputId": "ac3cd4aa-d655-4e5f-d1ac-7a6b0ade3a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/ml\"\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "action.ipynb\t output1\t\tUCF101\n",
            "action_v2.ipynb  output_200\t\tUCF101_test\n",
            "extra\t\t output_500epoch_rgb\tv_ApplyEyeMakeup_g01_c01.avi\n",
            "n\t\t output_smallepoch_rgb\n",
            "output\t\t results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XPE_0uYgYCWX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import os\n",
        "import json\n",
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import (Activation, Conv3D, Dense, Dropout, Flatten,\n",
        "                          MaxPooling3D)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib\n",
        "#import pydot\n",
        "#matplotlib.use('AGG')\n",
        "import matplotlib.pyplot as plt\n",
        "depth=18\n",
        "w=50\n",
        "h=50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OiwUk3Aj1kgK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYjTed9ZYD4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def video3d(filename):\n",
        "        cap = cv2.VideoCapture(filename)\n",
        "        nframe = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "        \n",
        "        frames = [x * nframe / depth for x in range(depth)]\n",
        "        \n",
        "        framearray = []\n",
        "\n",
        "        for i in range(depth):\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, frames[i])\n",
        "           # wf = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  \n",
        "            #hf = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "            ret, frame = cap.read()\n",
        "            #print(\"vvvvvvv\")\n",
        "            #print(wf,hf)\n",
        "            frame = cv2.resize(frame, (w,h))\n",
        "            framearray.append(frame)#cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        cap.release()\n",
        "        return np.array(framearray)\n",
        "#c=video3d('/content/drive/My Drive/ml/v_ApplyEyeMakeup_g01_c01.avi')\n",
        "#print(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "37Ckd-x_atcm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_UCF_classname(filename):\n",
        "        return filename[filename.find('_') + 1:filename.find('_', 2)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oirxq43Pbr7i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loaddata(video_dir,nclass, result_dir):\n",
        "    files = os.listdir(video_dir)\n",
        "    X = []\n",
        "    labels = []\n",
        "    labellist = []\n",
        "\n",
        "    #pbar = tqdm(total=len(files))\n",
        "    for v in files:\n",
        "        v1 = os.path.join(video_dir, v)\n",
        "        vfiles=os.listdir(v1)\n",
        "        for filename in vfiles:\n",
        "          #pbar.update(1)\n",
        "            if filename == '.DS_Store':\n",
        "                continue\n",
        "            name = os.path.join(v1, filename)\n",
        "            #print(files)\n",
        "            label = get_UCF_classname(filename)\n",
        "            if label not in labellist:\n",
        "                if len(labellist) >= nclass:\n",
        "                    continue\n",
        "                labellist.append(label)\n",
        "            labels.append(label)\n",
        "\n",
        "            X.append(video3d(name))\n",
        "\n",
        "      #pbar.close()\n",
        "    with open(os.path.join(result_dir, 'classes.txt'), 'w') as fp:\n",
        "        for i in range(len(labellist)):\n",
        "            fp.write('{}\\n'.format(labellist[i]))\n",
        "\n",
        "    for num, label in enumerate(labellist):\n",
        "        for i in range(len(labels)):\n",
        "            if label == labels[i]:\n",
        "                labels[i] = num\n",
        "    #v=np.array(X)            \n",
        "    #print(v.shape)\n",
        "    return np.array(X).transpose((0, 2, 3, 4, 1)), labels\n",
        "x,y=loaddata('/content/drive/My Drive/ml/UCF101',6,'/content/drive/My Drive/ml/results')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nzOml4jyuGoU",
        "colab_type": "code",
        "outputId": "e9f4e569-113c-429b-e59e-a7f274baa2ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F5WuiRDE0RVu",
        "colab_type": "code",
        "outputId": "12b3c42a-10bd-4b61-bb59-a0023afe0f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "noofclass=6\n",
        "fname_npz = 'datasett_{}_{}.npz'.format(\n",
        "        noofclass,depth)#class,depth,skip\n",
        "X = x.reshape((x.shape[0], w, h, depth, 3))\n",
        "Y = np_utils.to_categorical(y, noofclass)\n",
        "\n",
        "X = X.astype('float32')\n",
        "np.savez(fname_npz, X=X, Y=Y)\n",
        "print('Saved dataset to dataset.npz.')\n",
        "print('X_shape:{}\\nY_shape:{}'.format(X.shape, Y.shape))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved dataset to dataset.npz.\n",
            "X_shape:(784, 50, 50, 18, 3)\n",
            "Y_shape:(784, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mVs8VmG5_i-b",
        "colab_type": "code",
        "outputId": "ce987647-5a63-48b9-ae89-1d3023f092ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), input_shape=(\n",
        "    X.shape[1:]), border_mode='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(128, kernel_size=(3, 3, 3), border_mode='same'))\n",
        "model.add(Activation('softmax'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), border_mode='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv3D(128, kernel_size=(3, 3, 3), border_mode='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(256, kernel_size=(3, 3, 3), border_mode='same'))\n",
        "model.add(Activation('softmax'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), border_mode='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='sigmoid'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(noofclass, activation='softmax'))\n",
        "#sgd = SGD(lr=0.005, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=categorical_crossentropy,optimizer=Adam(), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, kernel_size=(3, 3, 3), input_shape=(50, 50, 1..., padding=\"same\")`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, kernel_size=(3, 3, 3), padding=\"same\")`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, kernel_size=(3, 3, 3), padding=\"same\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, kernel_size=(3, 3, 3), padding=\"same\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_1 (Conv3D)            (None, 50, 50, 18, 64)    5248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 50, 50, 18, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 50, 50, 18, 128)   221312    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 50, 50, 18, 128)   0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 17, 17, 6, 128)    0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 17, 17, 6, 128)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 17, 17, 6, 128)    442496    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 17, 17, 6, 128)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            (None, 17, 17, 6, 256)    884992    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 17, 17, 6, 256)    0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 6, 6, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              18875392  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 6150      \n",
            "=================================================================\n",
            "Total params: 20,435,590\n",
            "Trainable params: 20,435,590\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vLs6wDj9WW0y",
        "colab_type": "code",
        "outputId": "a456685a-c391-4999-b093-cf3aef6e4b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "pip install pydot\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-cddc4f7c8745>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install pydot\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bob3mgvYBohB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plot_model(model, show_shapes=True,to_file=os.path.join('/content/drive/My Drive/ml/output', 'model.png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hSSrNgPDCI4b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=43)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-U9gvb7CRup",
        "colab_type": "code",
        "outputId": "609d37c6-6d8a-4ec8-b187-fe7def4080fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7557
        }
      },
      "cell_type": "code",
      "source": [
        "hist=model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=15,\n",
        "                        epochs=150, verbose=1, shuffle=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 627 samples, validate on 157 samples\n",
            "Epoch 1/500\n",
            "627/627 [==============================] - 82s 131ms/step - loss: 2.2710 - acc: 0.1914 - val_loss: 2.1602 - val_acc: 0.1465\n",
            "Epoch 2/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 2.0879 - acc: 0.1340 - val_loss: 1.9690 - val_acc: 0.1401\n",
            "Epoch 3/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 2.0685 - acc: 0.1643 - val_loss: 1.9800 - val_acc: 0.1465\n",
            "Epoch 4/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 2.0648 - acc: 0.1722 - val_loss: 1.8677 - val_acc: 0.1465\n",
            "Epoch 5/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 1.9962 - acc: 0.1738 - val_loss: 1.8360 - val_acc: 0.1975\n",
            "Epoch 6/500\n",
            "627/627 [==============================] - 75s 119ms/step - loss: 1.9119 - acc: 0.1978 - val_loss: 1.6117 - val_acc: 0.3121\n",
            "Epoch 7/500\n",
            "627/627 [==============================] - 74s 119ms/step - loss: 1.6429 - acc: 0.3461 - val_loss: 1.2845 - val_acc: 0.4586\n",
            "Epoch 8/500\n",
            "627/627 [==============================] - 74s 119ms/step - loss: 1.3237 - acc: 0.4817 - val_loss: 1.1131 - val_acc: 0.5796\n",
            "Epoch 9/500\n",
            "627/627 [==============================] - 75s 119ms/step - loss: 0.9984 - acc: 0.5997 - val_loss: 0.8835 - val_acc: 0.6369\n",
            "Epoch 10/500\n",
            "627/627 [==============================] - 74s 119ms/step - loss: 0.7968 - acc: 0.7065 - val_loss: 0.8272 - val_acc: 0.6879\n",
            "Epoch 11/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.6360 - acc: 0.7656 - val_loss: 0.7711 - val_acc: 0.7070\n",
            "Epoch 12/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.4827 - acc: 0.8309 - val_loss: 0.5901 - val_acc: 0.7580\n",
            "Epoch 13/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3870 - acc: 0.8517 - val_loss: 0.5698 - val_acc: 0.7643\n",
            "Epoch 14/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3338 - acc: 0.8931 - val_loss: 0.5543 - val_acc: 0.8025\n",
            "Epoch 15/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2901 - acc: 0.8804 - val_loss: 0.5597 - val_acc: 0.7516\n",
            "Epoch 16/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2487 - acc: 0.9234 - val_loss: 0.4796 - val_acc: 0.8153\n",
            "Epoch 17/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2571 - acc: 0.9091 - val_loss: 0.4218 - val_acc: 0.8471\n",
            "Epoch 18/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2336 - acc: 0.9219 - val_loss: 0.5038 - val_acc: 0.8280\n",
            "Epoch 19/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3257 - acc: 0.8724 - val_loss: 0.4981 - val_acc: 0.8089\n",
            "Epoch 20/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2611 - acc: 0.9027 - val_loss: 0.5218 - val_acc: 0.7834\n",
            "Epoch 21/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1930 - acc: 0.9346 - val_loss: 0.4989 - val_acc: 0.8217\n",
            "Epoch 22/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2629 - acc: 0.9123 - val_loss: 0.6141 - val_acc: 0.7771\n",
            "Epoch 23/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2675 - acc: 0.9011 - val_loss: 0.4666 - val_acc: 0.8280\n",
            "Epoch 24/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1523 - acc: 0.9394 - val_loss: 0.4858 - val_acc: 0.8471\n",
            "Epoch 25/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1813 - acc: 0.9314 - val_loss: 0.4562 - val_acc: 0.8217\n",
            "Epoch 26/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2850 - acc: 0.8963 - val_loss: 0.4640 - val_acc: 0.8025\n",
            "Epoch 27/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1996 - acc: 0.9298 - val_loss: 0.4094 - val_acc: 0.8535\n",
            "Epoch 28/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1356 - acc: 0.9490 - val_loss: 0.4613 - val_acc: 0.8408\n",
            "Epoch 29/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1336 - acc: 0.9522 - val_loss: 0.3338 - val_acc: 0.8599\n",
            "Epoch 30/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2481 - acc: 0.8995 - val_loss: 1.7371 - val_acc: 0.5987\n",
            "Epoch 31/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.5787 - acc: 0.7990 - val_loss: 0.4835 - val_acc: 0.8280\n",
            "Epoch 32/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2904 - acc: 0.8884 - val_loss: 0.5110 - val_acc: 0.7452\n",
            "Epoch 33/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2239 - acc: 0.9155 - val_loss: 0.4955 - val_acc: 0.7516\n",
            "Epoch 34/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1068 - acc: 0.9633 - val_loss: 0.4255 - val_acc: 0.8217\n",
            "Epoch 35/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2041 - acc: 0.9123 - val_loss: 0.5652 - val_acc: 0.8280\n",
            "Epoch 36/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1552 - acc: 0.9490 - val_loss: 0.4398 - val_acc: 0.8535\n",
            "Epoch 37/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1064 - acc: 0.9490 - val_loss: 0.4214 - val_acc: 0.8535\n",
            "Epoch 38/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0731 - acc: 0.9761 - val_loss: 0.4644 - val_acc: 0.8408\n",
            "Epoch 39/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0666 - acc: 0.9761 - val_loss: 0.4304 - val_acc: 0.8471\n",
            "Epoch 40/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0569 - acc: 0.9761 - val_loss: 0.5268 - val_acc: 0.8217\n",
            "Epoch 41/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0809 - acc: 0.9713 - val_loss: 0.5601 - val_acc: 0.8344\n",
            "Epoch 42/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0837 - acc: 0.9697 - val_loss: 0.4362 - val_acc: 0.8153\n",
            "Epoch 43/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0660 - acc: 0.9793 - val_loss: 0.4802 - val_acc: 0.8153\n",
            "Epoch 44/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1041 - acc: 0.9585 - val_loss: 0.4732 - val_acc: 0.8471\n",
            "Epoch 45/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3815 - acc: 0.8836 - val_loss: 0.4546 - val_acc: 0.8471\n",
            "Epoch 46/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1607 - acc: 0.9442 - val_loss: 0.6506 - val_acc: 0.7962\n",
            "Epoch 47/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1465 - acc: 0.9442 - val_loss: 0.4083 - val_acc: 0.8599\n",
            "Epoch 48/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3147 - acc: 0.8852 - val_loss: 0.9608 - val_acc: 0.6306\n",
            "Epoch 49/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.5013 - acc: 0.8134 - val_loss: 0.3890 - val_acc: 0.8854\n",
            "Epoch 50/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1552 - acc: 0.9458 - val_loss: 0.4791 - val_acc: 0.8344\n",
            "Epoch 51/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 1.3060 - acc: 0.5407 - val_loss: 1.0010 - val_acc: 0.5669\n",
            "Epoch 52/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 1.5777 - acc: 0.4179 - val_loss: 1.1989 - val_acc: 0.4968\n",
            "Epoch 53/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 1.2015 - acc: 0.5327 - val_loss: 0.9959 - val_acc: 0.6051\n",
            "Epoch 54/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 1.1199 - acc: 0.5789 - val_loss: 0.9471 - val_acc: 0.6051\n",
            "Epoch 55/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.8349 - acc: 0.6906 - val_loss: 0.9312 - val_acc: 0.6561\n",
            "Epoch 56/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.9084 - acc: 0.6571 - val_loss: 1.1975 - val_acc: 0.5860\n",
            "Epoch 57/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.9848 - acc: 0.6364 - val_loss: 0.7800 - val_acc: 0.6815\n",
            "Epoch 58/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.7162 - acc: 0.7209 - val_loss: 0.7242 - val_acc: 0.7070\n",
            "Epoch 59/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.6869 - acc: 0.7464 - val_loss: 1.0985 - val_acc: 0.6115\n",
            "Epoch 60/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.7585 - acc: 0.7257 - val_loss: 0.6838 - val_acc: 0.7643\n",
            "Epoch 61/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.8143 - acc: 0.6938 - val_loss: 0.6158 - val_acc: 0.7197\n",
            "Epoch 62/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.5036 - acc: 0.8198 - val_loss: 0.6892 - val_acc: 0.7516\n",
            "Epoch 63/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.4171 - acc: 0.8485 - val_loss: 0.6927 - val_acc: 0.7261\n",
            "Epoch 64/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3678 - acc: 0.8565 - val_loss: 0.3660 - val_acc: 0.8535\n",
            "Epoch 65/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3197 - acc: 0.8660 - val_loss: 0.5465 - val_acc: 0.8153\n",
            "Epoch 66/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2304 - acc: 0.9219 - val_loss: 0.4562 - val_acc: 0.8089\n",
            "Epoch 67/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2348 - acc: 0.9107 - val_loss: 0.4733 - val_acc: 0.8025\n",
            "Epoch 68/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2541 - acc: 0.9139 - val_loss: 0.4188 - val_acc: 0.8662\n",
            "Epoch 69/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2151 - acc: 0.9107 - val_loss: 0.4714 - val_acc: 0.8280\n",
            "Epoch 70/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2206 - acc: 0.9219 - val_loss: 0.3755 - val_acc: 0.8981\n",
            "Epoch 71/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1366 - acc: 0.9458 - val_loss: 0.4638 - val_acc: 0.8535\n",
            "Epoch 72/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2508 - acc: 0.9075 - val_loss: 0.4606 - val_acc: 0.8217\n",
            "Epoch 73/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0762 - acc: 0.9729 - val_loss: 0.3394 - val_acc: 0.8981\n",
            "Epoch 74/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0992 - acc: 0.9585 - val_loss: 0.3355 - val_acc: 0.8726\n",
            "Epoch 75/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1458 - acc: 0.9553 - val_loss: 0.4906 - val_acc: 0.8280\n",
            "Epoch 76/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1862 - acc: 0.9298 - val_loss: 0.4013 - val_acc: 0.8599\n",
            "Epoch 77/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1226 - acc: 0.9617 - val_loss: 0.3449 - val_acc: 0.8471\n",
            "Epoch 78/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0858 - acc: 0.9649 - val_loss: 0.2431 - val_acc: 0.9045\n",
            "Epoch 79/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0722 - acc: 0.9697 - val_loss: 0.2751 - val_acc: 0.9172\n",
            "Epoch 80/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0568 - acc: 0.9793 - val_loss: 0.2519 - val_acc: 0.8917\n",
            "Epoch 81/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0445 - acc: 0.9856 - val_loss: 0.2789 - val_acc: 0.8981\n",
            "Epoch 82/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0357 - acc: 0.9872 - val_loss: 0.2697 - val_acc: 0.9172\n",
            "Epoch 83/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0655 - acc: 0.9777 - val_loss: 0.2445 - val_acc: 0.9236\n",
            "Epoch 84/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0217 - acc: 0.9936 - val_loss: 0.3106 - val_acc: 0.9108\n",
            "Epoch 85/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0517 - acc: 0.9809 - val_loss: 0.2912 - val_acc: 0.8917\n",
            "Epoch 86/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0684 - acc: 0.9713 - val_loss: 0.3103 - val_acc: 0.9045\n",
            "Epoch 87/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0360 - acc: 0.9872 - val_loss: 0.2912 - val_acc: 0.9172\n",
            "Epoch 88/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0196 - acc: 0.9936 - val_loss: 0.3083 - val_acc: 0.9172\n",
            "Epoch 89/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0145 - acc: 0.9952 - val_loss: 0.3066 - val_acc: 0.8917\n",
            "Epoch 90/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0365 - acc: 0.9872 - val_loss: 0.4107 - val_acc: 0.9108\n",
            "Epoch 91/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.2482 - val_acc: 0.9236\n",
            "Epoch 92/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0170 - acc: 0.9936 - val_loss: 0.3590 - val_acc: 0.9108\n",
            "Epoch 93/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0213 - acc: 0.9904 - val_loss: 0.3233 - val_acc: 0.9299\n",
            "Epoch 94/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0093 - acc: 0.9968 - val_loss: 0.2491 - val_acc: 0.9363\n",
            "Epoch 95/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0208 - acc: 0.9936 - val_loss: 0.4275 - val_acc: 0.9045\n",
            "Epoch 96/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0182 - acc: 0.9936 - val_loss: 0.3255 - val_acc: 0.9045\n",
            "Epoch 97/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0920 - acc: 0.9649 - val_loss: 0.3219 - val_acc: 0.8854\n",
            "Epoch 98/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0887 - acc: 0.9633 - val_loss: 0.5728 - val_acc: 0.8280\n",
            "Epoch 99/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.1013 - acc: 0.9585 - val_loss: 0.3671 - val_acc: 0.8790\n",
            "Epoch 100/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.1026 - acc: 0.9601 - val_loss: 0.4093 - val_acc: 0.8599\n",
            "Epoch 101/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.1020 - acc: 0.9601 - val_loss: 0.3371 - val_acc: 0.8662\n",
            "Epoch 102/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0580 - acc: 0.9713 - val_loss: 0.3040 - val_acc: 0.9045\n",
            "Epoch 103/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0233 - acc: 0.9936 - val_loss: 0.2668 - val_acc: 0.9490\n",
            "Epoch 104/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0234 - acc: 0.9872 - val_loss: 0.3553 - val_acc: 0.8981\n",
            "Epoch 105/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0210 - acc: 0.9936 - val_loss: 0.3425 - val_acc: 0.9236\n",
            "Epoch 106/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0173 - acc: 0.9904 - val_loss: 0.3390 - val_acc: 0.9299\n",
            "Epoch 107/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0374 - acc: 0.9856 - val_loss: 0.5090 - val_acc: 0.8726\n",
            "Epoch 108/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0419 - acc: 0.9856 - val_loss: 0.2821 - val_acc: 0.8917\n",
            "Epoch 109/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0343 - acc: 0.9920 - val_loss: 0.5073 - val_acc: 0.8408\n",
            "Epoch 110/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0387 - acc: 0.9856 - val_loss: 0.2380 - val_acc: 0.9299\n",
            "Epoch 111/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0261 - acc: 0.9904 - val_loss: 0.3416 - val_acc: 0.8790\n",
            "Epoch 112/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0401 - acc: 0.9872 - val_loss: 0.3009 - val_acc: 0.9172\n",
            "Epoch 113/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1054 - acc: 0.9617 - val_loss: 0.2790 - val_acc: 0.8981\n",
            "Epoch 114/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0958 - acc: 0.9633 - val_loss: 0.3369 - val_acc: 0.8854\n",
            "Epoch 115/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0441 - acc: 0.9856 - val_loss: 0.3431 - val_acc: 0.9045\n",
            "Epoch 116/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0326 - acc: 0.9904 - val_loss: 0.2618 - val_acc: 0.9108\n",
            "Epoch 117/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0253 - acc: 0.9872 - val_loss: 0.2694 - val_acc: 0.8854\n",
            "Epoch 118/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0414 - acc: 0.9841 - val_loss: 0.3093 - val_acc: 0.9045\n",
            "Epoch 119/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0767 - acc: 0.9729 - val_loss: 0.3420 - val_acc: 0.8726\n",
            "Epoch 120/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0235 - acc: 0.9920 - val_loss: 0.4375 - val_acc: 0.8854\n",
            "Epoch 121/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0674 - acc: 0.9665 - val_loss: 0.3798 - val_acc: 0.9045\n",
            "Epoch 122/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0761 - acc: 0.9745 - val_loss: 0.3826 - val_acc: 0.8599\n",
            "Epoch 123/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.1001 - acc: 0.9665 - val_loss: 0.3413 - val_acc: 0.8854\n",
            "Epoch 124/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0491 - acc: 0.9809 - val_loss: 0.4125 - val_acc: 0.8854\n",
            "Epoch 125/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0900 - acc: 0.9617 - val_loss: 0.4256 - val_acc: 0.8599\n",
            "Epoch 126/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0711 - acc: 0.9713 - val_loss: 0.4309 - val_acc: 0.8662\n",
            "Epoch 127/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0558 - acc: 0.9761 - val_loss: 0.4233 - val_acc: 0.8662\n",
            "Epoch 128/500\n",
            "627/627 [==============================] - 74s 117ms/step - loss: 0.0373 - acc: 0.9856 - val_loss: 0.4173 - val_acc: 0.8726\n",
            "Epoch 129/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1194 - acc: 0.9601 - val_loss: 0.3435 - val_acc: 0.8599\n",
            "Epoch 130/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.6203 - acc: 0.7847 - val_loss: 0.4277 - val_acc: 0.8025\n",
            "Epoch 131/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.5847 - acc: 0.7990 - val_loss: 0.8653 - val_acc: 0.7134\n",
            "Epoch 132/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.6130 - acc: 0.7863 - val_loss: 0.4618 - val_acc: 0.8025\n",
            "Epoch 133/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.4160 - acc: 0.8581 - val_loss: 0.4912 - val_acc: 0.8217\n",
            "Epoch 134/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3372 - acc: 0.8915 - val_loss: 0.4905 - val_acc: 0.8408\n",
            "Epoch 135/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.4596 - acc: 0.8309 - val_loss: 0.4387 - val_acc: 0.8408\n",
            "Epoch 136/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2763 - acc: 0.9011 - val_loss: 0.3385 - val_acc: 0.8599\n",
            "Epoch 137/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2851 - acc: 0.8963 - val_loss: 0.3890 - val_acc: 0.8662\n",
            "Epoch 138/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1852 - acc: 0.9378 - val_loss: 0.4207 - val_acc: 0.8471\n",
            "Epoch 139/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1478 - acc: 0.9585 - val_loss: 0.9482 - val_acc: 0.7325\n",
            "Epoch 140/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.7405 - acc: 0.7863 - val_loss: 0.4662 - val_acc: 0.8408\n",
            "Epoch 141/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3994 - acc: 0.8708 - val_loss: 0.8533 - val_acc: 0.7261\n",
            "Epoch 142/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1885 - acc: 0.9362 - val_loss: 0.3352 - val_acc: 0.8726\n",
            "Epoch 143/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1313 - acc: 0.9522 - val_loss: 0.3728 - val_acc: 0.8790\n",
            "Epoch 144/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0752 - acc: 0.9793 - val_loss: 0.3319 - val_acc: 0.9045\n",
            "Epoch 145/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1391 - acc: 0.9442 - val_loss: 0.4606 - val_acc: 0.8662\n",
            "Epoch 146/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0844 - acc: 0.9729 - val_loss: 0.3295 - val_acc: 0.8790\n",
            "Epoch 147/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0793 - acc: 0.9745 - val_loss: 0.3215 - val_acc: 0.8917\n",
            "Epoch 148/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0892 - acc: 0.9777 - val_loss: 0.3199 - val_acc: 0.8917\n",
            "Epoch 149/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0902 - acc: 0.9713 - val_loss: 0.1983 - val_acc: 0.9172\n",
            "Epoch 150/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0303 - acc: 0.9920 - val_loss: 0.2060 - val_acc: 0.9045\n",
            "Epoch 151/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0460 - acc: 0.9809 - val_loss: 0.1821 - val_acc: 0.9236\n",
            "Epoch 152/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0409 - acc: 0.9856 - val_loss: 0.2613 - val_acc: 0.8981\n",
            "Epoch 153/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0169 - acc: 0.9968 - val_loss: 0.3156 - val_acc: 0.8854\n",
            "Epoch 154/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0892 - acc: 0.9713 - val_loss: 0.2978 - val_acc: 0.9108\n",
            "Epoch 155/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0762 - acc: 0.9745 - val_loss: 0.4256 - val_acc: 0.8662\n",
            "Epoch 156/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0308 - acc: 0.9904 - val_loss: 0.3325 - val_acc: 0.8726\n",
            "Epoch 157/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0552 - acc: 0.9809 - val_loss: 0.2619 - val_acc: 0.9236\n",
            "Epoch 158/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0204 - acc: 0.9936 - val_loss: 0.3282 - val_acc: 0.9045\n",
            "Epoch 159/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0206 - acc: 0.9936 - val_loss: 0.2434 - val_acc: 0.9299\n",
            "Epoch 160/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0084 - acc: 0.9968 - val_loss: 0.2589 - val_acc: 0.9299\n",
            "Epoch 161/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0064 - acc: 0.9984 - val_loss: 0.2603 - val_acc: 0.9427\n",
            "Epoch 162/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0198 - acc: 0.9920 - val_loss: 0.3604 - val_acc: 0.8981\n",
            "Epoch 163/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1503 - acc: 0.9490 - val_loss: 0.4767 - val_acc: 0.8790\n",
            "Epoch 164/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.0615 - acc: 0.9681 - val_loss: 0.3255 - val_acc: 0.9108\n",
            "Epoch 165/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3336 - acc: 0.8884 - val_loss: 1.3933 - val_acc: 0.5924\n",
            "Epoch 166/500\n",
            "627/627 [==============================] - 74s 119ms/step - loss: 1.0446 - acc: 0.6715 - val_loss: 0.5798 - val_acc: 0.7707\n",
            "Epoch 167/500\n",
            "627/627 [==============================] - 74s 119ms/step - loss: 0.5887 - acc: 0.7879 - val_loss: 0.9764 - val_acc: 0.6688\n",
            "Epoch 168/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.7308 - acc: 0.7735 - val_loss: 0.7686 - val_acc: 0.7580\n",
            "Epoch 169/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.6433 - acc: 0.7671 - val_loss: 0.6108 - val_acc: 0.7452\n",
            "Epoch 170/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.4217 - acc: 0.8469 - val_loss: 0.4239 - val_acc: 0.8471\n",
            "Epoch 171/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2700 - acc: 0.9027 - val_loss: 0.3058 - val_acc: 0.8726\n",
            "Epoch 172/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2606 - acc: 0.9043 - val_loss: 0.4890 - val_acc: 0.8153\n",
            "Epoch 173/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2069 - acc: 0.9266 - val_loss: 0.3755 - val_acc: 0.8599\n",
            "Epoch 174/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2557 - acc: 0.9139 - val_loss: 0.5227 - val_acc: 0.7962\n",
            "Epoch 175/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3949 - acc: 0.8788 - val_loss: 0.8061 - val_acc: 0.6497\n",
            "Epoch 176/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.7228 - acc: 0.7480 - val_loss: 0.5851 - val_acc: 0.7771\n",
            "Epoch 177/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3714 - acc: 0.8596 - val_loss: 0.4450 - val_acc: 0.8089\n",
            "Epoch 178/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3639 - acc: 0.8612 - val_loss: 0.4801 - val_acc: 0.8089\n",
            "Epoch 179/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3099 - acc: 0.8772 - val_loss: 0.5965 - val_acc: 0.7389\n",
            "Epoch 180/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2708 - acc: 0.8868 - val_loss: 0.5281 - val_acc: 0.7962\n",
            "Epoch 181/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.1732 - acc: 0.9282 - val_loss: 0.3441 - val_acc: 0.8471\n",
            "Epoch 182/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2292 - acc: 0.9139 - val_loss: 0.8323 - val_acc: 0.7452\n",
            "Epoch 183/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.9918 - acc: 0.6922 - val_loss: 0.5923 - val_acc: 0.7643\n",
            "Epoch 184/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 1.1241 - acc: 0.6284 - val_loss: 0.9669 - val_acc: 0.6624\n",
            "Epoch 185/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 1.0974 - acc: 0.5981 - val_loss: 0.8649 - val_acc: 0.6752\n",
            "Epoch 186/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.8264 - acc: 0.6986 - val_loss: 0.7130 - val_acc: 0.7070\n",
            "Epoch 187/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.6474 - acc: 0.7671 - val_loss: 0.8033 - val_acc: 0.6943\n",
            "Epoch 188/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.5714 - acc: 0.7863 - val_loss: 0.8549 - val_acc: 0.7389\n",
            "Epoch 189/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.7506 - acc: 0.7049 - val_loss: 0.6702 - val_acc: 0.7707\n",
            "Epoch 190/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.4867 - acc: 0.8118 - val_loss: 0.4781 - val_acc: 0.8408\n",
            "Epoch 191/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3290 - acc: 0.8820 - val_loss: 0.4199 - val_acc: 0.8280\n",
            "Epoch 192/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.4749 - acc: 0.8293 - val_loss: 0.7032 - val_acc: 0.7643\n",
            "Epoch 193/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.4567 - acc: 0.8341 - val_loss: 0.7468 - val_acc: 0.7516\n",
            "Epoch 194/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.5058 - acc: 0.8341 - val_loss: 0.4785 - val_acc: 0.8153\n",
            "Epoch 195/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3517 - acc: 0.8565 - val_loss: 0.4628 - val_acc: 0.8408\n",
            "Epoch 196/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3778 - acc: 0.8660 - val_loss: 0.4423 - val_acc: 0.8153\n",
            "Epoch 197/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2751 - acc: 0.8979 - val_loss: 0.3819 - val_acc: 0.8153\n",
            "Epoch 198/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.3237 - acc: 0.8740 - val_loss: 0.5191 - val_acc: 0.8408\n",
            "Epoch 199/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2727 - acc: 0.8963 - val_loss: 0.4410 - val_acc: 0.8471\n",
            "Epoch 200/500\n",
            "627/627 [==============================] - 74s 118ms/step - loss: 0.2010 - acc: 0.9250 - val_loss: 0.4541 - val_acc: 0.8535\n",
            "Epoch 201/500\n",
            " 15/627 [..............................] - ETA: 1:07 - loss: 1.1643 - acc: 0.8000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-1e1d2486173f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist=model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=15,\n\u001b[0;32m----> 2\u001b[0;31m                         epochs=500, verbose=1, shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-2_lgx0-CbV4",
        "colab_type": "code",
        "outputId": "b34eda04-bd1a-40b2-e59c-6e410ab2a72f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "  model.evaluate(X_test, Y_test, verbose=0)\n",
        "  model_json = model.to_json()\n",
        "  if not os.path.isdir('/content/drive/My Drive/ml/output'):\n",
        "      os.makedirs('/content/drive/My Drive/ml/output')\n",
        "  with open(os.path.join('/content/drive/My Drive/ml/output', 'ucf101_3dcnnmodel_50_50_30_rgb.json'), 'w') as json_file:\n",
        "      json_file.write(model_json)\n",
        "  model.save_weights(os.path.join('/content/drive/My Drive/ml/output', 'ucf101_3dcnnmodel_50_50_30_rgb.hd5'))\n",
        "\n",
        "  loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "  print('Test loss:', loss)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.34954394191313704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8p7oDvAQMlFo",
        "colab_type": "code",
        "outputId": "e049cb8b-fa90-4746-e171-d2551e345b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8726114615513261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fCb1h3I6Mqdl",
        "colab_type": "code",
        "outputId": "94cc89ac-ca1f-491c-ea97-4730517549da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1294
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "with open('/content/drive/My Drive/ml/results/classes.txt', 'r') as f:\n",
        "    class_names = f.readlines()\n",
        "    f.close()\n",
        "with open('/content/drive/My Drive/ml/output/ucf101_3dcnnmodel_50_50_30_rgb.json', 'r') as f:\n",
        "    model1 = model_from_json(f.read())\n",
        "model1.load_weights('/content/drive/My Drive/ml/output/ucf101_3dcnnmodel_50_50_30_rgb.hd5', by_name=True)\n",
        "\n",
        "# read video\n",
        "video = '/content/drive/My Drive/ml/UCF101/ApplyEyeMakeup/v_ApplyEyeMakeup_g24_c02.avi'\n",
        "cap = cv2.VideoCapture(video)\n",
        "\n",
        "vid = []\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    #print(\"aaaaaaaaaaaaaa\")\n",
        "    if ret:\n",
        "        #print(\"bbbbbbbbb\")\n",
        "        tmp=frame\n",
        "       # tmp = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        vid.append(cv2.resize(tmp, (50,50)))\n",
        "        if len(vid) == 30:\n",
        "            i=np.array(vid)\n",
        "           # print(i.shape)\n",
        "           # j = np.transpose(i, (1,2,0))\n",
        "            test = i.reshape((1,50, 50, 30, 3))\n",
        "            pred = model1.predict(test)\n",
        "            label = np.argmax(pred[0])\n",
        "            print(label)\n",
        "            cv2.putText(frame, class_names[label].split(' ')[-1].strip(), (20, 20),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n",
        "                        (0, 0, 255), 1)\n",
        "            cv2.putText(frame, \"prob: %.4f\" % pred[0][label], (20, 40),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n",
        "                        (0, 0, 255), 1)\n",
        "            vid.pop(0)\n",
        "        #cv2.imshow('result', frame)\n",
        "        #cv2.waitKey(10)\n",
        "    else:\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eb0jEBZfjzNs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}